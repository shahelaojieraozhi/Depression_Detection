{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        
        {
            "name": "Python: 当前文件",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "cwd": "${fileDirname}",  // 设置当前工作目录为当前文件所在目录
            "justMyCode": false,
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
            }
        },

        {
            "name": "sh_file_debug",
            "type": "debugpy",
            "request": "attach",
            "justMyCode": false,
            "connect": {
                "host": "localhost",
                "port": 10086
            }
        },

        {
            "name": "torchr_ex2",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/yuanz/anaconda3/envs/hznet/bin/torchrun", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--nnodes",
                "1",
                "--nproc-per-node",
                "1",
                "${file}",
                "--model_name_or_path",
                "my_model_xxx"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
            }
        },
        {
            "name": "torchrun_ex1",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/yuanz/anaconda3/envs/hznet/bin/torchrun", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--nnodes",
                "1",
                "--nproc-per-node",
                "1",
                "${file}",
                "--model_name_or_path",
                "my_model"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
            }
        },
        {
            "name": "torchrun_copy",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/yuanz/anaconda3/envs/hznet/bin/torchrun", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--nnodes",
                "1",
                "--nproc-per-node",
                "1",
                "${file}",
                "--model_name_or_path",
                "my_model"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
            }
        },
        {
            "name": "ds_zero2",
            "type": "debugpy",
            "request": "launch",
            "program": "/homedata/chenzhigang/miniconda3/envs/llava/bin/deepspeed", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--num_nodes",
                "1",
                "--num_gpus",
                "2",
                "${file}",
                "--deepspeed",
                "./config/default_offlload_zero2.json",
                "--model_name_or_path",
                "my_model",
                "--output_dir",
                "hhh"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
            }
        },
        {
            "name": "llava_ds_zero3",
            "type": "debugpy",
            "request": "launch",
            "program": "/root/miniconda3/envs/llava/bin/deepspeed", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_nodes", "1",
                "--num_gpus", "1",
                "${file}",
                "--deepspeed",
                "/project/code/raozhi/gfslt_llm/LLaVA/scripts/zero3.json",
                "--lora_enable", "True",
                "--lora_r", "128", 
                "--lora_alpha", "256",
                "--mm_projector_lr" ,"2e-5",
                "--model_name_or_path" ,"/project/code/raozhi/pretrained_models/lmsys/vicuna-7b-v1.5",
                "--version", "v1", 
                "--data_path" ,"/project/code/raozhi/gfslt_llm/LLaVA/playground/data/llava_v1_5_1k.json",
                "--image_folder", "/project/code/raozhi/LLaVA/playground/data",
                "--vision_tower", "/project/code/raozhi/pretrained_models/clip-vit-large-patch14-336",
                "--pretrain_mm_mlp_adapter" ,"/project/code/raozhi/pretrained_models/llava-v1.5-7b/mm_projector.bin",
                "--mm_projector_type", "mlp2x_gelu",
                "--mm_vision_select_layer", "-2",
                "--mm_use_im_start_end", "False",
                "--mm_use_im_patch_token", "False",
                "--image_aspect_ratio",  "pad",
                "--group_by_modality_length", "True",
                "--bf16", "True",
                "--output_dir" , "/project/code/raozhi/gfslt_llm/LLaVA/llava-v1.5-7b-debug",
                "--num_train_epochs" , "1",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size" , "1",
                "--gradient_accumulation_steps" ,"1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps" , "50000",
                "--save_total_limit" ,"1",
                "--learning_rate", "2e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--model_max_length" ,"2048",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--lazy_preprocess", "True",
                "--report_to", "tensorboard"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "3",
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
            }
        },
        {
            "name": "llava_slt_ds_zero3",
            "type": "debugpy",
            "request": "launch",
            "program": "/share/hyhong/miniconda3/envs/rz/bin/deepspeed", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_nodes", "1",
                "--num_gpus", "4",
                "${file}",   //  "--include", "localhost:3",
                "--deepspeed",
                "/share/raozhi/slt/LLaVA/scripts/zero3.json",
                "--mm_projector_lr" ,"2e-5",
                "--model_name_or_path" ,"/share/raozhi/pretrained_models/lmsys/vicuna-7b-v1.5",
                "--version", "v1", 
                "--data_path" ,"/share/raozhi/slt/LLaVA/slt_llava_train.json",
                "--image_folder", "/project/code/raozhi/video_datasets/OpenASL",
                "--vision_tower", "/share/raozhi/pretrained_models/MBart_trimmed_OpenASL",
                "--mm_projector_type", "mlp2x_gelu",
                "--mm_vision_select_layer", "-2",
                "--mm_use_im_start_end", "False",
                "--mm_use_im_patch_token", "False",
                "--image_aspect_ratio",  "pad",
                "--group_by_modality_length", "True",
                "--bf16", "False",
                "--output_dir" , "/share/raozhi/slt/LLaVA/checkpoints/slt_llava-v1.5-7b_lora",
                "--num_train_epochs" , "1",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size" , "1",
                "--gradient_accumulation_steps" ,"1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps" , "50000",
                "--save_total_limit" ,"1",
                "--learning_rate", "2e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "False",
                "--model_max_length" ,"2048",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--lazy_preprocess", "True",
                "--downsample", "True" ,
                "--stride", "1" ,
                "--is_train", "True",
                "--feature_max_length", "300" ,
                "--report_to", "tensorboard",
            ]
        },
        {
            "name": "llava_slt_ds_zero3_single_gpu",
            "type": "debugpy",
            "request": "launch",
            "program": "/root/miniconda3/envs/llava/bin/deepspeed", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_nodes", "1",
                "--num_gpus", "1",
                "${file}",   //  "--include", "localhost:3",
                "--deepspeed",
                "/project/code/raozhi/gfslt_llm/LLaVA/scripts/zero3.json",
                "--lora_enable", "True",
                "--lora_r", "128", 
                "--lora_alpha", "256",
                "--mm_projector_lr" ,"2e-5",
                "--model_name_or_path" ,"/project/code/raozhi/pretrained_models/lmsys/vicuna-7b-v1.5",
                "--version", "v1", 
                "--data_path" ,"/project/code/raozhi/video_datasets/OpenASL/slt_llava_test.json",
                "--image_folder", "/project/code/raozhi/video_datasets/OpenASL",
                "--vision_tower", "/project/code/raozhi/pretrained_models/mytran_OpenASL_512",
                "--mm_projector_type", "mlp2x_gelu",
                "--mm_vision_select_layer", "-2",
                "--mm_use_im_start_end", "False",
                "--mm_use_im_patch_token", "False",
                "--image_aspect_ratio",  "pad",
                "--group_by_modality_length", "True",
                "--bf16", "True",
                "--output_dir" , "/project/code/raozhi/gfslt_llm/LLaVA/llava-v1.5-7b-debug",
                "--num_train_epochs" , "1",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size" , "1",
                "--gradient_accumulation_steps" ,"1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps" , "50000",
                "--save_total_limit" ,"1",
                "--learning_rate", "2e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--model_max_length" ,"2048",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--lazy_preprocess", "True",
                "--downsample", "True" ,
                "--stride", "1" ,
                "--is_train", "True",
                "--feature_max_length", "300" ,
                "--report_to", "tensorboard",
            ]
        },

        {
            "name": "slt_infer",
            "type": "debugpy",
            "request": "launch",
            "program": "/share/hyhong/miniconda3/envs/rz/bin/deepspeed", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--include", "localhost:1", //"--include", "localhost:3",
                "--master_port", "12346",
                "llava/train/llava_slt_inference_batch.py",   //"${file}",
                "--lora_enable", "True",
                "--model_name_or_path" ,"/share/raozhi/pretrained_models/lmsys/vicuna-7b-v1.5",
                "--version", "v1", 
                "--data_path" ,"/share/raozhi/slt/LLaVA/debug_slt_llava_test_filter_bj.json",
                "--image_folder", "/share/raozhi/data_bin/slt",
                "--vision_tower", "/share/raozhi/pretrained_models/MBart_trimmed_OpenASL",
                "--pretrain_mm_mlp_adapter", "/share/raozhi/slt/LLaVA/checkpoints/slt_llava-v1.5-7b_lora_debug/non_lora_trainables.bin",
                "--mm_projector_type", "mlp2x_gelu",
                "--mm_vision_select_layer", "-2",
                "--mm_use_im_start_end", "False",
                "--mm_use_im_patch_token", "False",
                "--image_aspect_ratio",  "pad",
                "--group_by_modality_length", "True",
                "--bf16", "False",
                "--output_dir" , "checkpoints/slt_llava_dd-v1.5-7b",
                "--num_train_epochs" , "1",
                "--batch_size", "2",
                "--gradient_accumulation_steps" ,"1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps" , "50000",
                "--save_total_limit" ,"1",
                "--learning_rate", "2e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "False",
                "--model_max_length" ,"2048",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--lazy_preprocess", "True",
                "--downsample", "True" ,
                "--stride", "1" ,
                "--is_train", "True",
                "--feature_max_length", "300" ,
                "--report_to", "tensorboard",
            ]
        },

        {
            "name": "videollama2_ds_zero3",
            "type": "debugpy",
            "request": "launch",
            "program": "/homedata/chenzhigang/miniconda3/envs/zhi/bin/torchrun", //"${file}",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_nodes", "1",
                "--num_gpus", "1",
                "${file}",
                "--deepspeed",
                "/mnt/data/chenzhigang/code/gfslt/SLT_LLaVA/scripts/zero3.json",
                "--lora_enable", "True",
                "--lora_r", "128", 
                "--lora_alpha", "256",
                "--mm_projector_lr" ,"2e-5",
                "--model_name_or_path" ,"/mnt/data/chenzhigang/code/gfslt/LLaVA/lmsys/vicuna-7b-v1.5",
                "--version", "v1", 
                "--data_path" ,"/mnt/data/chenzhigang/code/gfslt/LLaVA/playground/data/llava_v1_5_mix665k.json",
                "--image_folder", "/mnt/data/chenzhigang/code/gfslt/LLaVA/playground/data",
                "--vision_tower", "/mnt/data/chenzhigang/code/gfslt/LLaVA/clip-vit-large-patch14-336",
                "--pretrain_mm_mlp_adapter" ,"/mnt/data/chenzhigang/code/gfslt/LLaVA/llava-v1.5-7b/mm_projector.bin",
                "--mm_projector_type", "mlp2x_gelu",
                "--mm_vision_select_layer", "-2",
                "--mm_use_im_start_end", "False",
                "--mm_use_im_patch_token", "False",
                "--image_aspect_ratio",  "pad",
                "--group_by_modality_length", "True",
                "--bf16", "True",
                "--output_dir" , "/mnt/data/chenzhigang/code/gfslt/SLT_LLaVA/checkpoints/llava-v1.5-7b-lora",
                "--num_train_epochs" , "1",
                "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size" , "1",
                "--gradient_accumulation_steps" ,"1",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps" , "50000",
                "--save_total_limit" ,"1",
                "--learning_rate", "2e-4",
                "--weight_decay", "0.",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--model_max_length" ,"2048",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--lazy_preprocess", "True",
                "--report_to", "wandb"
            ]
        }
    ]
}